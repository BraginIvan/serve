def delete_mar_file_from_model_store(model_store=None, model_mar=None) -> None: ...
class TorchServeHandler:
    def __init__(self, exec_env: str = "docker", cuda_version: str = "cu102", gpus=None, torchserve_docker_image=None, backend_profiling=None, connection=None, is_local_execution: bool = False) -> None: ...
    def create_and_update_workflow_archive(self, workflow_name, spec_file_name, handler_file_name, batch_size, workers, batch_delay, retry_attempts, timeout_ms) -> None: ...
    def download_workflow_artifacts(self, workflow_name, model_urls, specfile_url, workflow_handler_url) -> None: ...
    def getAPIS(self) -> None: ...
    def plot_stats_graph(self, model_name, mode_name, num_workers, batch_size) -> None: ...
    def prepare_common_dependency(self) -> None: ...
    def register_model(self, url, workers, batch_delay, batch_size, model_name: str = "benchmark") -> None: ...
    def register_workflow(self, url) -> None: ...
    def setup_torchserve(self, virtual_env_name=None) -> None: ...
    def start_recording_docker_stats(self) -> None: ...
    def start_torchserve_docker(self, stop_torchserve: bool = True) -> None: ...
    def start_torchserve_local(self, virtual_env_name=None, stop_torchserve: bool = True) -> None: ...
    def stop_recording_docker_stats(self, model_name, num_workers, batch_size) -> None: ...
    def stop_torchserve(self, exec_env: str = "docker", virtual_env_name=None) -> None: ...
    def unregister_model(self, model_name: str = "benchmark") -> None: ...
    def unregister_workflow(self, workflow_name) -> None: ...

